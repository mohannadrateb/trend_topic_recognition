{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-27 14:58:26,234 https://flair.informatik.hu-berlin.de/resources/embeddings/token/de-crawl-fasttext-300d-1M.vectors.npy not found in cache, downloading to /tmp/tmpvrfy_91w\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1199998928/1199998928 [25:11<00:00, 794120.84B/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-27 15:23:37,957 copying /tmp/tmpvrfy_91w to cache at /home/mendu/.flair/embeddings/de-crawl-fasttext-300d-1M.vectors.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-27 15:23:48,276 removing temp file /tmp/tmpvrfy_91w\n",
      "2021-11-27 15:23:48,906 https://flair.informatik.hu-berlin.de/resources/embeddings/token/de-crawl-fasttext-300d-1M not found in cache, downloading to /tmp/tmpc1nnxa9r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42677439/42677439 [00:51<00:00, 822156.29B/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-27 15:24:41,419 copying /tmp/tmpc1nnxa9r to cache at /home/mendu/.flair/embeddings/de-crawl-fasttext-300d-1M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-27 15:24:41,508 removing temp file /tmp/tmpc1nnxa9r\n"
     ]
    }
   ],
   "source": [
    "from flair.embeddings import WordEmbeddings\n",
    "from flair.data import Sentence\n",
    "\n",
    "# init embedding\n",
    "glove_embedding = WordEmbeddings('de-crawl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(word):\n",
    "    # create sentence.\n",
    "    sentence = Sentence(word)\n",
    "\n",
    "    # embed a sentence using glove.\n",
    "    glove_embedding.embed(sentence)\n",
    "\n",
    "    # now check out the embedded tokens.\n",
    "    for token in sentence:\n",
    "        #print(token)\n",
    "        #print(token.embedding)\n",
    "        torch_tensor = token.embedding\n",
    "        np_arr = torch_tensor.cpu().detach().numpy()\n",
    "        return(np_arr)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0312,  0.0246,  0.0563, -0.    ,  0.0175, -0.06  , -0.0356,\n",
       "       -0.0589,  0.0037,  0.0257, -0.0082, -0.048 ,  0.0091, -0.0106,\n",
       "       -0.0848, -0.1172,  0.0391, -0.0382, -0.0252, -0.0812,  0.0134,\n",
       "        0.0119,  0.027 ,  0.015 ,  0.0026,  0.0277,  0.0092,  0.0222,\n",
       "        0.0159,  0.002 ,  0.0974, -0.0257, -0.0019, -0.0929,  0.0111,\n",
       "       -0.0111, -0.0229,  0.1161, -0.0345, -0.1042,  0.0099, -0.054 ,\n",
       "        0.0373, -0.0115, -0.0523, -0.0097,  0.0188,  0.0204,  0.0048,\n",
       "       -0.0762, -0.0294, -0.0072, -0.0143, -0.0305, -0.0112,  0.0083,\n",
       "       -0.0064,  0.0513, -0.0103, -0.102 , -0.0358, -0.0458, -0.0349,\n",
       "        0.0992,  0.0205, -0.0247,  0.0157, -0.0332,  0.009 , -0.1691,\n",
       "       -0.0371, -0.0963, -0.0576,  0.0081, -0.0069,  0.0516,  0.041 ,\n",
       "        0.0151,  0.0144, -0.0216,  0.0075,  0.0487, -0.0406, -0.0249,\n",
       "       -0.05  ,  0.1426, -0.0039, -0.0336,  0.0233, -0.0105,  0.0521,\n",
       "       -0.0111, -0.0382,  0.0133,  0.0094,  0.0949, -0.0411, -0.0459,\n",
       "        0.0366, -0.0104, -0.0681,  0.0263,  0.0282, -0.0437,  0.0337,\n",
       "       -0.0886,  0.0833,  0.0591, -0.0179, -0.0341, -0.0795, -0.0297,\n",
       "       -0.0136,  0.0484, -0.0286, -0.0006,  0.0382,  0.0124,  0.0391,\n",
       "       -0.0264,  0.002 ,  0.0577,  0.005 , -0.0272,  0.0909,  0.0731,\n",
       "       -0.1287, -0.0497, -0.0231,  0.0151,  0.0283,  0.0823,  0.0858,\n",
       "       -0.0419,  0.0569, -0.0159, -0.1065,  0.0483, -0.006 , -0.0076,\n",
       "        0.0393, -0.1747,  0.0414, -0.0384,  0.0136,  0.0011,  0.0433,\n",
       "        0.079 ,  0.0135,  0.0253,  0.0161, -0.0086, -0.0015, -0.0062,\n",
       "        0.0653,  0.0642, -0.0209, -0.0019,  0.0139,  0.0651, -0.0021,\n",
       "        0.0092,  0.0342, -0.0504, -0.0106,  0.048 , -0.008 ,  0.0036,\n",
       "        0.0526, -0.0184, -0.0748, -0.0344,  0.0342, -0.005 ,  0.0145,\n",
       "        0.0649,  0.0485, -0.0649, -0.1428, -0.0547, -0.0583, -0.004 ,\n",
       "       -0.0006, -0.0088, -0.0169, -0.0031,  0.095 ,  0.0281,  0.0118,\n",
       "        0.0121,  0.0038, -0.072 ,  0.0359,  0.0468,  0.0019,  0.1453,\n",
       "        0.0528,  0.0438, -0.0013, -0.0182, -0.0172,  0.0484, -0.0419,\n",
       "       -0.0097, -0.0214,  0.0242, -0.0335, -0.037 , -0.064 ,  0.0096,\n",
       "        0.0335,  0.0002,  0.0151,  0.0422,  0.0769,  0.0018, -0.0488,\n",
       "        0.0112,  0.0388, -0.0594,  0.0237,  0.0567, -0.0222,  0.007 ,\n",
       "       -0.0577,  0.056 , -0.0225, -0.0215,  0.0049, -0.0209,  0.0114,\n",
       "       -0.0463, -0.0025,  0.0077, -0.031 ,  0.043 , -0.0093, -0.035 ,\n",
       "        0.0875, -0.0294,  0.0175,  0.0272,  0.0008, -0.009 ,  0.0122,\n",
       "        0.0587, -0.0452, -0.027 , -0.0701, -0.1092,  0.038 ,  0.0366,\n",
       "        0.0296, -0.0711,  0.0003,  0.0199,  0.0263,  0.0345,  0.0298,\n",
       "        0.0096,  0.0226,  0.0079, -0.0768, -0.0049,  0.0297, -0.0385,\n",
       "       -0.1689, -0.0554, -0.04  ,  0.065 , -0.0539, -0.0188, -0.0989,\n",
       "        0.0383, -0.0623, -0.1054,  0.0891,  0.1049, -0.0642,  0.0287,\n",
       "       -0.0159,  0.0499,  0.0381,  0.0074, -0.0222,  0.0284,  0.0087,\n",
       "       -0.0491, -0.0543,  0.0834,  0.0813, -0.0232, -0.0336,  0.0044,\n",
       "        0.0357, -0.0105,  0.0571, -0.0355, -0.0302,  0.0523],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed('Alles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Embedding method with a cosine distance asses that our two sentences are similar to 72.58 %\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f0b45c28760>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gloveFile = \"glove.6B.50d.txt\"\n",
    "import numpy as np\n",
    "def loadGloveModel(gloveFile):\n",
    "    print (\"Loading Glove Model\")\n",
    "    with open(gloveFile, encoding=\"utf8\" ) as f:\n",
    "        content = f.readlines()\n",
    "    model = {}\n",
    "    for line in content:\n",
    "        splitLine = line.split()\n",
    "        word = splitLine[0]\n",
    "        embedding = np.array([float(val) for val in splitLine[1:]])\n",
    "        model[word] = embedding\n",
    "    print (\"Done.\",len(model),\" words loaded!\")\n",
    "    return model\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def preprocess(raw_text):\n",
    "\n",
    "    # keep only words\n",
    "    letters_only_text = re.sub(\"[^a-zA-Z]\", \" \", raw_text)\n",
    "\n",
    "    # convert to lower case and split \n",
    "    words = letters_only_text.lower().split()\n",
    "\n",
    "    # remove stopwords\n",
    "    stopword_set = set(stopwords.words(\"german\"))\n",
    "    cleaned_words = list(set([w for w in words if w not in stopword_set]))\n",
    "\n",
    "    return cleaned_words\n",
    "\n",
    "def cosine_distance_between_two_words(word1, word2):\n",
    "    import scipy\n",
    "    return (1- scipy.spatial.distance.cosine(embed(word1), embed(word2)))\n",
    "\n",
    "def calculate_heat_matrix_for_two_sentences(s1,s2):\n",
    "    s1 = preprocess(s1)\n",
    "    s2 = preprocess(s2)\n",
    "    result_list = [[cosine_distance_between_two_words(word1, word2) for word2 in s2] for word1 in s1]\n",
    "    result_df = pd.DataFrame(result_list)\n",
    "    result_df.columns = s2\n",
    "    result_df.index = s1\n",
    "    return result_df\n",
    "\n",
    "def cosine_distance_wordembedding_method(s1, s2):\n",
    "    import scipy\n",
    "    vector_1 = np.mean([embed(word) for word in preprocess(s1)],axis=0)\n",
    "    vector_2 = np.mean([embed(word) for word in preprocess(s2)],axis=0)\n",
    "    cosine = scipy.spatial.distance.cosine(vector_1, vector_2)\n",
    "    print('Word Embedding method with a cosine distance asses that our two sentences are similar to',round((1-cosine)*100,2),'%')\n",
    "\n",
    "def heat_map_matrix_between_two_sentences(s1,s2):\n",
    "    df = calculate_heat_matrix_for_two_sentences(s1,s2)\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig, ax = plt.subplots(figsize=(5,5)) \n",
    "    ax_blue = sns.heatmap(df, cmap=\"YlGnBu\")\n",
    "    # ax_red = sns.heatmap(df)\n",
    "    print(cosine_distance_wordembedding_method(s1, s2))\n",
    "    return ax_blue\n",
    "\n",
    "ss1 = 'AI Artificial Intelligence Machine Learning künstliche Intelligenz'\n",
    "ss2 = 'Der #ModernWorkplace als #DigitalColleague Ihrer Mitarbeiter - Unsinn oder doch bald Realität? Im #Webinar am 08.05. beantwortet unser Kollege @Twalz Ihre Fragen rund um den Einsatz von #ChatBots und #KI. Jetzt kostenfrei anmelden! https://t.co/bzvXKbHP9e /tir'\n",
    "\n",
    "#model = loadGloveModel(gloveFile)\n",
    "heat_map_matrix_between_two_sentences(ss1,ss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
